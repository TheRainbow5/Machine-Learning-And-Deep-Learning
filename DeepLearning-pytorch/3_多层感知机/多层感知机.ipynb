{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知机（MLP）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minist 用MLP实现，MLP也是使用pytorch实现的\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from  torch.utils  import data \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "    使用Fashion-MNIST图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''下载数据集'''\n",
    "# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n",
    "# 并除以255使得所有像素的数值均在0到1之间\n",
    "trans = transforms.ToTensor()\n",
    "#下载训练数据\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\",  #保存的目录\n",
    "    train=True,       #下载的是训练数据集\n",
    "    transform=trans,   #得到的是pytorch的tensor，而不是图片\n",
    "    download=True)  #从网上下载\n",
    "#下载测试数据\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=\"datasets\", train=False, transform=trans, download=True)\n",
    "len(mnist_train),len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''装载数据集'''\n",
    "data_loader_train=data.DataLoader(dataset=mnist_train,\n",
    "                                                batch_size=64,\n",
    "                                                shuffle=True)   #数据是否打乱\n",
    "data_loader_test=data.DataLoader(dataset=mnist_test,\n",
    "                                    batch_size=64,\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hidden,num_outputs=28*28,256,10\n",
    "lr=0.1\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''定义了一个隐藏层'''\n",
    "net=torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),   #将数据战平\n",
    "    torch.nn.Linear(num_inputs,num_hidden),  #隐藏层\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(num_hidden,num_outputs)  #输出层\n",
    ")\n",
    "'''定义权重'''\n",
    "def  init_w(m):\n",
    "    if type(m)==torch.nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight,std=0.01)\n",
    "net.apply(init_w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''相关优化器'''\n",
    "loss=torch.nn.CrossEntropyLoss()  #交叉熵\n",
    "optimizer=torch.optim.SGD(net.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'简单训练'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''简单训练'''\n",
    "d2l.train_ch3(net,data_loader_train,data_loader_test,loss,num_epochs,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.predict_ch3(net,data_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义预测准确率函数'''\n",
    "def acc(y_hat,y):\n",
    "    '''\n",
    "    :param y_hat: 接收二维张量，例如 torch.tensor([[1], [0]...])\n",
    "    :param y: 接收二维张量，例如 torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]...]) 三分类问题\n",
    "    :return:\n",
    "    '''\n",
    "    y_hat=y_hat.argmax(axis=1)\n",
    "    cmp=y_hat.type(y.dtype)==y  #数据类型是否相同\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "    \n",
    "class Accumulator():\n",
    "    ''' 对评估的正确数量和总数进行累加 '''\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "'''自定义每个批次训练函数'''\n",
    "def train_epoch_cha3(net,data_loader_train,loss,optimizer):\n",
    "    #判断是不是pytorch得model，如果是，就打开训练模式，pytorch得训练模式默认开启梯度更新\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.train()\n",
    "    #创建样本累加器【累加每批次的损失值、样本预测正确的个数、样本总数】\n",
    "    metric = Accumulator(3)  \n",
    "    for x,y in data_loader_train:\n",
    "        #前向传播获取预测结果\n",
    "        y_hat=net(x)\n",
    "        #计算损失\n",
    "        l=loss(y_hat,y) \n",
    "        #判断是pytorch自带得方法还是我们手写得方法（根据不同得方法有不同得处理方式）\n",
    "        if isinstance(optimizer,torch.optim.Optimizer):\n",
    "            #梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            #损失之求和，反向传播（pytorch自动进行了损失值计算）\n",
    "            l.backward()\n",
    "            #更新梯度\n",
    "            optimizer.step()\n",
    "            #累加个参数\n",
    "            metric.add(\n",
    "                float(l)*len(y),  #损失值总数\n",
    "                acc(y_hat,y),     #计算预测正确得总数\n",
    "                y.size().numel()  #样本总数\n",
    "            )\n",
    "    #返回平均损失值，预测正确得概率\n",
    "    return metric[0]/metric[2],metric[1]/metric[2]\n",
    "\n",
    "'''正式训练'''\n",
    "def train_cha3(num_epochs,net,data_loader_train,loss,optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        #返回平均损失值和正确率\n",
    "        train_metrics=train_epoch_cha3(net,data_loader_train,loss,optimizer)\n",
    "        print(f\"epoch{epoch+1}:loss={train_metrics[0]},acc={train_metrics[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1:loss=0.3681945420026779,acc=86.71%\n",
      "epoch2:loss=0.34939849710464477,acc=87.28%\n",
      "epoch3:loss=0.334820201532046,acc=87.88%\n",
      "epoch4:loss=0.31987783874670667,acc=88.43%\n",
      "epoch5:loss=0.3096299751520157,acc=88.81%\n",
      "epoch6:loss=0.30028981035550434,acc=89.05%\n",
      "epoch7:loss=0.291978483804067,acc=89.32%\n",
      "epoch8:loss=0.2833652744293213,acc=89.64%\n",
      "epoch9:loss=0.2762533922433853,acc=89.80%\n",
      "epoch10:loss=0.2684988775253296,acc=90.15%\n"
     ]
    }
   ],
   "source": [
    "train_cha3(num_epochs,net,data_loader_train,loss,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc=0.88%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8753"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''测试模型'''\n",
    "def test_cha3(net,test_iter):\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.eval()  #将模型设置为评估模式\n",
    "    metric=Accumulator(2)\n",
    "    for x,y in test_iter:\n",
    "        metric.add(\n",
    "            acc(net(x),y),  #计算准确个数\n",
    "            y.numel()  #测试样本总数\n",
    "        )\n",
    "    #返回模型得准确率\n",
    "    print(f\"test_acc={metric[0]/metric[1]:.2f}%\")\n",
    "    return metric[0]/metric[1]\n",
    "\n",
    "'''测试'''\n",
    "test_cha3(net,data_loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
