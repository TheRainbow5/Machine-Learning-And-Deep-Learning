{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 引言\n",
    "    残差神经网络(ResNet)是由微软研究院的何恺明、张祥雨、任少卿、孙剑等人提出的。ResNet 在2015 年的ILSVRC（ImageNet Large Scale Visual Recognition Challenge）中取得了冠军。残差神经网络的主要贡献是发现了“退化现象（Degradation）”，并针对退化现象发明了 “快捷连接（Shortcut connection）”，极大的消除了深度过大的神经网络训练困难问题。神经网络的“深度”首次突破了100层、最大的神经网络甚至超过了1000层。\n",
    "\n",
    "# 什么是ResNet？\n",
    "    ResNet是一种残差网络（由许多残差块组成），可以理解为一个子网络，这个子网络经过堆叠构成一个很深的网络。\n",
    "<img src=\"pic\\26.jpg\" width=\"500\"/>\n",
    "\n",
    "在2012年的ILSVRC挑战赛中，AlexNet取得了冠军，并且大幅度领先于第二名。由此引发了对AlexNet广泛研究，并让大家树立了一个信念——“越深网络准确率越高”。这个信念随着VGGNet、Inception v1、Inception v2、Inception v3不断验证、不断强化，得到越来越多的认可，但是，始终有一个问题无法回避，这个信念正确吗？\n",
    "\n",
    "# 为什么引入ResNet？\n",
    "\n",
    "通过实验，ResNet随着网络层不断的加深，模型的准确率先是不断的提高，达到最大值（准确率饱和），然后随着网络深度的继续增加，模型准确率毫无征兆的出现大幅度的降低。\n",
    "\n",
    "<img src=\"pic\\27.jpg\" width=\"300\"/>\n",
    "\n",
    "<img src=\"pic\\29.jpg\" width=\"500\" />\n",
    "\n",
    "如果一个模型够简单，那么可能值需要F1范围的东西。往往我们可以加更多层（到F6），使得模型能够学习到更大的东西。如上图，F3模型到目标的距离比F6模型更小，虽然F6的模型更加的复杂，但是实际上可能学偏了，这就是模型偏差。\n",
    "\n",
    "## 那应该如何解决这个问题呢？（核心思想）\n",
    "* 在每个模型中包含前面的模型，如图下侧所示\n",
    "## 残差块\n",
    "\n",
    "<img src=\"pic\\30.jpg\" width=\"500\"/>\n",
    "\n",
    "ResNet沿用了VGG完整3x3的卷积层设计。 \n",
    "\n",
    "残差块里首先有2个有相同输出通道数3x3的卷积层。 \n",
    "\n",
    "每个卷积层后接一个批量规范化层和ReLU激活函数。 \n",
    "\n",
    "然后我们通过跨层数据通路，跳过这2个卷积运算，将输入直接加在最后的ReLU激活函数前。\n",
    "\n",
    " **这样的设计要求2个卷积层的输出与输入形状一样，从而使它们可以相加**。 如果想改变通道数，就需要引入一个额外1x1的卷积层来将输入变换成需要的形状后再做相加运算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from  torch.utils import data \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: torch.Size([4, 3, 6, 6])\n",
      "output_shape: torch.Size([4, 3, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "    '''输入通道和输出通道相同，才能保证和输入数据相加'''\n",
    "    def __init__(self,input_channels,num_channels,\n",
    "                    use_1conv=False,stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1=torch.nn.Conv2d(input_channels,num_channels,kernel_size=3,padding=1,stride=stride)\n",
    "        self.conv2=torch.nn.Conv2d(num_channels,num_channels,kernel_size=3,padding=1)\n",
    "        #如果向改变通道数，使用1X1的卷积层来变换通道数\n",
    "        if use_1conv:  \n",
    "            self.conv3=torch.nn.Conv2d(input_channels,num_channels,kernel_size=1,stride=stride)\n",
    "        else:\n",
    "            self.conv3=None\n",
    "        #批量规范化  防止梯度爆炸或者消失\n",
    "        self.bn1=torch.nn.BatchNorm2d(num_channels)\n",
    "        self.bn2=torch.nn.BatchNorm2d(num_channels)\n",
    "        #激活函数\n",
    "        self.relu=torch.nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        y=self.relu(self.bn1(self.conv1(x)))\n",
    "        y=self.bn2(self.conv2(y))\n",
    "        if self.conv3:\n",
    "            x=self.conv3(x)\n",
    "        y+=x  #数据相加s\n",
    "        #y=self.relu(y)  #<-----------------------\n",
    "        return self.relu(y)\n",
    "\n",
    "blk=Resnet(3,3)\n",
    "x=torch.rand(4,3,6,6)\n",
    "y=blk.forward(x)\n",
    "print(\"input_shape:\",x.shape)\n",
    "print(\"output_shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape: torch.Size([4, 3, 6, 6])\n",
      "output_shape: torch.Size([4, 6, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 增加通道数\n",
    "blk=Resnet(3,6,use_1conv=True,stride=2)\n",
    "x=torch.rand(4,3,6,6)\n",
    "print(\"input_shape:\",x.shape)\n",
    "y=blk.forward(x)\n",
    "print(\"output_shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此代码生成两种类型的网络： 一种是当use_1x1conv=False时，应用ReLU非线性函数之前，将输入添加到输出。 另一种是当use_1x1conv=True时，添加通过1x1卷积调整通道和分辨率。\n",
    "\n",
    "<img src=\"pic\\31.jpg\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet模型\n",
    "    ResNet的前两层跟之前介绍的GoogLeNet中的一样： 在输出通道数为64、步幅为2的7x7卷积层后，接步幅为2的的3x3最大汇聚层。 不同之处在于ResNet每个卷积层后增加了批量规范化层\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一层卷积层\n",
    "b1=torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),\n",
    "    torch.nn.BatchNorm2d(64),  #防止梯度爆炸或者消失\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet则使用4个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块。 第一个模块的通道数同输入通道数一致。 由于之前已经使用了步幅为2的最大汇聚层，所以无须减小高和宽。 之后的每个模块在第一个残差块里将上一个模块的通道数翻倍，并将高和宽减半。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_channels:输入通道\n",
    "num_channels:输出通道\n",
    "num_resuduals:每个残差块的卷积层数量\n",
    "'''\n",
    "def resnet_block(input_channels,num_channels,num_resuduals,first_blk=False):\n",
    "    blk=[]\n",
    "    for i in range(num_resuduals):\n",
    "        #对第一个残差块的第一个块进行特殊处理（改变x的通道数，和输出相加）\n",
    "        if i==0 and not first_blk:\n",
    "            blk.append(Resnet(input_channels,num_channels,\n",
    "                                use_1conv=True,stride=2))\n",
    "        else:\n",
    "            blk.append(Resnet(num_channels,num_channels))\n",
    "    return blk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet():\n",
    "    #第一层卷积层\n",
    "    b1=torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),\n",
    "        torch.nn.BatchNorm2d(64),  #防止梯度爆炸或者消失\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "    )\n",
    "     #一个残差块不需要调整通道数\n",
    "    b2 = torch.nn.Sequential(*resnet_block(64, 64, 2, first_blk=True)) \n",
    "    b3 = torch.nn.Sequential(*resnet_block(64, 128, 2))\n",
    "    b4 = torch.nn.Sequential(*resnet_block(128, 256, 2))\n",
    "    b5 = torch.nn.Sequential(*resnet_block(256, 512, 2))\n",
    "    net=torch.nn.Sequential(\n",
    "        b1,b2,b3,b4,b5,\n",
    "        torch.nn.AdaptiveAvgPool2d((1,1)),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(512,10)\n",
    "    )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个模块有4个卷积层（不包括恒等映射1x1的卷积层）。 加上第一个7x7卷积层和最后一个全连接层，共有18层。 因此，这种模型通常被称为ResNet-18。 通过配置不同的通道数和模块里的残差块数可以得到不同的ResNet模型，例如更深的含152层的ResNet-152。 虽然ResNet的主体架构跟GoogLeNet类似，但ResNet架构更简单，修改也更方便。这些因素都导致了ResNet迅速被广泛使用。 图7.6.4描述了完整的ResNet-18。\n",
    "\n",
    "<img src=\"pic\\32.jpg\" width=\"200\"/>  \n",
    "<img src=\"pic\\33.jpg\" width=\"200\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Resnet(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Resnet(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Resnet(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Resnet(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Resnet(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Resnet(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Resnet(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Resnet(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=ResNet()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size,resize):\n",
    "    # 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n",
    "    # 并除以255使得所有像素的数值均在0到1之间\n",
    "    trans =[transforms.ToTensor()]\n",
    "    #修改图片大小\n",
    "    if resize:\n",
    "        trans.insert(0,transforms.Resize(resize)) \n",
    "    trans=transforms.Compose(trans)\n",
    "    #下载训练数据\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"datasets\",  #保存的目录\n",
    "        train=True,       #下载的是训练数据集\n",
    "        transform=trans,   #得到的是pytorch的tensor，而不是图片\n",
    "        download=True)  #从网上下载\n",
    "    print(type(mnist_train))    \n",
    "    #下载测试数据\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"datasets\", train=False, transform=trans, download=True)\n",
    "    print(mnist_train)\n",
    "    print(len(mnist_train),len(mnist_test))\n",
    "    #装载数据\n",
    "    data_loader_train=data.DataLoader(dataset=mnist_train,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=True)   #数据是否打乱\n",
    "    data_loader_test=data.DataLoader(dataset=mnist_test,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True)\n",
    "    return data_loader_train,data_loader_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "* wxw：输入图片的大小\n",
    "* fxf：卷积核大小\n",
    "* s：步长（stride）\n",
    "* p：padding\n",
    "### 卷积层后的输出大小公式\n",
    "* 计算公式：N=(w-f+2p)/s+1**小数向上取整**\n",
    "\n",
    "### 池化层的输出大小公式\n",
    "* N'=(N-f)/s+1 **小数向上取整**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''定义预测准确率函数'''\n",
    "def acc(y_hat,y):\n",
    "    '''\n",
    "    :param y_hat: 接收二维张量，例如 torch.tensor([[1], [0]...])\n",
    "    :param y: 接收二维张量，例如 torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]...]) 三分类问题\n",
    "    :return:\n",
    "    '''\n",
    "    y_hat=y_hat.argmax(axis=1)\n",
    "    cmp=y_hat.type(y.dtype)==y  #数据类型是否相同\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "    \n",
    "class Accumulator():\n",
    "    ''' 对评估的正确数量和总数进行累加 '''\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "'''自定义每个批次训练函数'''\n",
    "def train_epoch(net,train_iter,loss,optimizer,device):\n",
    "    #判断是不是pytorch得model，如果是，就打开训练模式，pytorch得训练模式默认开启梯度更新\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.train()\n",
    "    #创建样本累加器【累加每批次的损失值、样本预测正确的个数、样本总数】\n",
    "    metric = Accumulator(3)  \n",
    "    for x,y in train_iter:\n",
    "        x=x.to(device)                            #<----------------------GPU\n",
    "        y=y.to(device)\n",
    "        #前向传播获取预测结果\n",
    "        y_hat=net(x)\n",
    "        #计算损失\n",
    "        l=loss(y_hat,y) \n",
    "        #判断是pytorch自带得方法还是我们手写得方法（根据不同得方法有不同得处理方式）\n",
    "        if isinstance(optimizer,torch.optim.Optimizer):\n",
    "            #梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            #损失之求和，反向传播（pytorch自动进行了损失值计算）\n",
    "            l.backward()\n",
    "            #更新梯度\n",
    "            optimizer.step()\n",
    "            #累加个参数\n",
    "            metric.add(\n",
    "                float(l)*len(y),  #损失值总数\n",
    "                acc(y_hat,y),     #计算预测正确得总数\n",
    "                y.size().numel()  #样本总数\n",
    "            )\n",
    "    #返回平均损失值，预测正确得概率\n",
    "    return metric[0]/metric[2],metric[1]/metric[2]\n",
    "\n",
    "'''模型测试'''\n",
    "def test_epoch(net,test_iter,device):\n",
    "    if isinstance(net,torch.nn.Module):\n",
    "        net.eval()  #将模型设置为评估模式\n",
    "    metric=Accumulator(2)\n",
    "    for x,y in test_iter:\n",
    "        x=x.to(device)                            #<----------------------GPU\n",
    "        y=y.to(device)\n",
    "        metric.add(\n",
    "            acc(net.forward(x),y),  #计算准确个数\n",
    "            y.numel()  #测试样本总数\n",
    "        )\n",
    "    return metric[0]/metric[1]\n",
    "\n",
    "'''正式训练'''\n",
    "def train_LeNet(num_epochs,trian_iter,test_iter,lr):\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    net=ResNet()  #VGG网络\n",
    "    net=net.to(device)  #将网络放在gpu或cpu运行<--------------\n",
    "    loss_list=[]\n",
    "    train_acc=[]\n",
    "    test_acc=[]\n",
    "    #初始化权重\n",
    "    def init_weight(m):\n",
    "        if type(m)==torch.nn.Linear or type(m)==torch.nn.Conv2d:\n",
    "            torch.nn.init.xavier_normal_(m.weight)\n",
    "    net.apply(init_weight)\n",
    "    #损失函数\n",
    "    loss=torch.nn.CrossEntropyLoss()\n",
    "    #优化器\n",
    "    optimizer=torch.optim.SGD(net.parameters(),lr=lr)\n",
    "    #训练\n",
    "    for epoch in range(num_epochs):\n",
    "        #返回平均损失值和正确率\n",
    "        train_metrics=train_epoch(net,trian_iter,loss,optimizer,device)  #<-----训练\n",
    "        loss_list.append(train_metrics[0])  #保存loss\n",
    "        train_acc.append(train_metrics[1])   #保存准确率\n",
    "        #测试集\n",
    "        test_metric=test_epoch(net,test_iter,device)     #<-------------测试\n",
    "        test_acc.append(test_metric)\n",
    "        print(f\"epoch{epoch+1}:loss={train_metrics[0]},train_acc={train_metrics[1]*100:.2f}%,test_acc={test_metric*100:.2f}%\")\n",
    "    \n",
    "    return loss_list,train_acc,test_acc\n",
    "\n",
    "'''可视化'''\n",
    "def draw(num_epochs,loss_list,train_acc,test_acc):\n",
    "    fig,ax=plt.subplots()   #定义画布\n",
    "    ax.grid(True)          #添加网格\n",
    "    ax.set_xlabel(\"epoch\")\n",
    "    #ax.set_ylim(0,1)\n",
    "\n",
    "    ax.plot(range(num_epochs),loss_list,label=\"loss\")\n",
    "    ax.plot(range(num_epochs),train_acc,dashes=[6, 2],label=\"train\")\n",
    "    ax.plot(range(num_epochs),test_acc,dashes=[6, 2],label=\"test\")\n",
    "    ax.legend(title=\"ResNet\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 10])\n",
      "<class 'torchvision.datasets.mnist.FashionMNIST'>\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: datasets\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n",
      "60000 10000\n",
      "cuda\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bdai/jie/10_现在卷积网络/model/3_ResNet.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=9'>10</a>\u001b[0m train_iter,test_iter\u001b[39m=\u001b[39mload_data(batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,resize\u001b[39m=\u001b[39m\u001b[39m224\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m#训练\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=11'>12</a>\u001b[0m loss_list,train_acc,test_acc\u001b[39m=\u001b[39mtrain_LeNet(num_epochs,train_iter,test_iter,lr)\n",
      "\u001b[1;32m/home/bdai/jie/10_现在卷积网络/model/3_ResNet.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain_LeNet\u001b[0;34m(num_epochs, trian_iter, test_iter, lr)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=88'>89</a>\u001b[0m \u001b[39m#训练\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=89'>90</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=90'>91</a>\u001b[0m     \u001b[39m#返回平均损失值和正确率\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=91'>92</a>\u001b[0m     train_metrics\u001b[39m=\u001b[39mtrain_epoch(net,trian_iter,loss,optimizer,device)  \u001b[39m#<-----训练\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=92'>93</a>\u001b[0m     loss_list\u001b[39m.\u001b[39mappend(train_metrics[\u001b[39m0\u001b[39m])  \u001b[39m#保存loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=93'>94</a>\u001b[0m     train_acc\u001b[39m.\u001b[39mappend(train_metrics[\u001b[39m1\u001b[39m])   \u001b[39m#保存准确率\u001b[39;00m\n",
      "\u001b[1;32m/home/bdai/jie/10_现在卷积网络/model/3_ResNet.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(net, train_iter, loss, optimizer, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=34'>35</a>\u001b[0m y\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=35'>36</a>\u001b[0m \u001b[39m#前向传播获取预测结果\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=36'>37</a>\u001b[0m y_hat\u001b[39m=\u001b[39mnet(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=37'>38</a>\u001b[0m \u001b[39m#计算损失\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B114.213.162.194/home/bdai/jie/10_%E7%8E%B0%E5%9C%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/model/3_ResNet.ipynb#ch0000017vscode-remote?line=38'>39</a>\u001b[0m l\u001b[39m=\u001b[39mloss(y_hat,y) \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:168\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m     bn_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    163\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[39mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[39mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m    169\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    170\u001b[0m     \u001b[39m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean\n\u001b[1;32m    172\u001b[0m     \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats\n\u001b[1;32m    173\u001b[0m     \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrack_running_stats \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    176\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    177\u001b[0m     bn_training,\n\u001b[1;32m    178\u001b[0m     exponential_average_factor,\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    180\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2438\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2435\u001b[0m \u001b[39mif\u001b[39;00m training:\n\u001b[1;32m   2436\u001b[0m     _verify_batch_size(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[0;32m-> 2438\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mbatch_norm(\n\u001b[1;32m   2439\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mcudnn\u001b[39m.\u001b[39;49menabled\n\u001b[1;32m   2440\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "num_epochs=10\n",
    "lr=0.01\n",
    "#查看网络参数\n",
    "x=torch.randn(size=(1,1,224,224))\n",
    "for blk in ResNet():\n",
    "    x=blk(x)\n",
    "    print(blk.__class__.__name__,'output shape:\\t',x.shape)\n",
    "#数据集\n",
    "train_iter,test_iter=load_data(batch_size=64,resize=224)\n",
    "#训练\n",
    "loss_list,train_acc,test_acc=train_LeNet(num_epochs,train_iter,test_iter,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "draw(num_epochs,loss_list,train_acc,test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小结\n",
    "* 利用残差块（residual blocks）可以训练出一个有效的深层神经网络：输入可以通过层间的残余连接更快地向前传播。\n",
    "* 残差网络（ResNet）对随后的深层神经网络设计产生了深远影响。\n",
    "* 加快收敛的速度\n",
    "* 防止梯度爆炸或者消失"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
