{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 案例：泰坦尼克号乘客⽣存预测\n",
    "## 学习目标\n",
    "* 通过案例进⼀步掌握决策树算法api的具体使⽤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 1 54.0]\n",
      " [3.0 1 13.0]\n",
      " [3.0 1 28.0]\n",
      " ...\n",
      " [3.0 1 25.0]\n",
      " [3.0 1 29.881137667304014]\n",
      " [3.0 1 29.881137667304014]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer  #处理缺失值\n",
    "from sklearn.model_selection import train_test_split\n",
    "data=pd.read_csv(r\"D:\\program_Lab_Report\\machine_learning\\100day\\code\\5_决策树\\泰塔尼克号.csv\")\n",
    "'''确定特征值'''\n",
    "x=data.iloc[:,[2,4,5,]].values\n",
    "y=data.iloc[:,1].values\n",
    "'''处理缺失值'''\n",
    "#用均值代替缺失值\n",
    "imputer=SimpleImputer(strategy=\"mean\")  #用均值替代缺失值\n",
    "x[:,[0,2]]=imputer.fit_transform(x[:,[0,2]])\n",
    "'''文本数据数值化'''\n",
    "#由于文本数据只有female和male，所以本项目将其分为0和1\n",
    "for item in x:\n",
    "    if item[1]=='male':\n",
    "        item[1]=1\n",
    "    if item[1]=='female':\n",
    "        item[1]=0\n",
    "'''数据划分'''\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "    sklearn.tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,random_state=None)\n",
    "* criterion\n",
    "    * 特征选择标准\n",
    "    * \"gini\"或者\"entropy\"，前者代表基尼系数，后者代表信息增益。⼀默认\"gini\"，即CART算法。\n",
    "\n",
    "* min_samples_split\n",
    "    * 内部节点再划分所需最⼩样本数\n",
    "    * 这个值限制了⼦树继续划分的条件，如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进⾏划分。 默认是2.如果样本量不⼤，不需要管这个值。如果样本量数量级⾮常⼤，则推荐增⼤这个值。我之前的⼀个项⽬例⼦，有⼤概10万样本，建⽴决策树时，我选择了min_samples_split=10。可以作为参考。\n",
    "\n",
    "* min_samples_leaf\n",
    "    * 叶⼦节点最少样本数\n",
    "    * 这个值限制了叶⼦节点最少的样本数，如果某叶⼦节点数⽬⼩于样本数，则会和兄弟节点⼀起被剪枝。默认是1,可以输⼊最少的样本数的整数，或者最少样本数占样本总数的百分⽐。如果样本量不⼤，不需要管这个值。如果样本量数量级⾮常⼤，则推荐增⼤这个值。之前的10万样本项⽬使⽤min_samples_leaf的值为5，仅供参考。\n",
    "* max_depth\n",
    "    * 决策树最⼤深度\n",
    "    * 决策树的最⼤深度，默认可以不输⼊，如果不输⼊的话，决策树在建⽴⼦树的时候不会限制⼦树的深度。⼀般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最⼤深度，具体的取值取决于数据的分布。常⽤的可以取值10-100之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc=DecisionTreeClassifier(criterion='entropy',max_depth=6)\n",
    "dc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8664122137404581\n"
     ]
    }
   ],
   "source": [
    "#测试集\n",
    "test_prd=dc.predict(x_test)\n",
    "\n",
    "test_score=dc.score(x_test,y_test)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树可视化\n",
    "* 网址http://webgraphviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "export_graphviz(dc, out_file=r\"tree.dot\", feature_names=['age', 'pclass','sex'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f03fb8992b0e5aa6a67cd56eb653950a01f214acb97d94a2178dd1aa47d1bcf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
