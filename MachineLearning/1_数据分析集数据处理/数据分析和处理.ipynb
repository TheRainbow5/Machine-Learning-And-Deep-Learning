{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：导入必要的库\n",
    "\n",
    "numpy和pandas是我们每次都需要导入的库。\n",
    "* Numpy包含数学计算函数。\n",
    "* Pandas用于导入和管理数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''求均值和方差'''\n",
    "# 调出numpy\n",
    "import numpy as np\n",
    "df = [21, 22, 30, 23, 15, 12]  # 要计算的数值\n",
    "# 求均值\n",
    "mean = np.mean(df)\n",
    "# 求方差\n",
    "var = np.var(df)\n",
    "# 求标准差\n",
    "std = np.std(df, ddof=1)\n",
    "# 数值输出,2f为保留两位小数\n",
    "print(\"平均值为：%.2f\" % mean)\n",
    "print(\"方 差 为：%.2f\" % var)\n",
    "print(\"标准差为：%.2f\" % std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步：导入数据集\n",
    "\n",
    "数据集通常以.csv格式提供。\n",
    "\n",
    "CSV文件以纯文本存储表格数据。\n",
    "\n",
    "文件的每一行都是数据记录，我们使用pandas库的read_csv方法读取本地CSV文件作为数据中的自变量和因变量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(r'D:\\program_Lab_Report\\machine_learning\\100day\\datasets\\Data.csv')\n",
    "x=df.iloc[:,:-1].values  #矩阵\n",
    "y=df.iloc[:,3].values  #向量\n",
    "print(x)\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理丢失的数据\n",
    "\n",
    "我们得到的数据很少是完整的，数据可能因为各种原因丢失，\n",
    "\n",
    "为了不降低机器学习模型的性能，需要处理数据。\n",
    "* 用整列的**平均值**或**中间值**替换丢失的数据\n",
    "\n",
    "我们用sklearn.preprocess库中的Imputer类完成这一项任务。\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer=SimpleImputer(strategy=\"mean\")  #用均值替代缺失值\n",
    "x[:,1:3]=imputer.fit_transform(x[:,1:3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步：分析数据类型\n",
    "\n",
    "分类数据指的是：含有标签值而不是数字值的变量，取值范围通常是固定的。\n",
    "\n",
    "例如“Yes”和\"No”不能用于模型的数学计算，所以需要解析成数字。为实现这一功能。\n",
    "\n",
    "我们从sklearn.preprocesing库导入LabelEncoder类，完成这一项任务。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "#将分类数据转化为数字\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_x=LabelEncoder()  #初始化\n",
    "x[:,0]=labelencoder_x.fit_transform(x[:,0])  #选取第一列数据\n",
    "#创建虚变量\n",
    "ct=ColumnTransformer([(\"Country\",OneHotEncoder(),[0])],remainder=\"passthrough\")\n",
    "x=ct.fit_transform(x)\n",
    "\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "\n",
    "print(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五步：将数据集划分为训练集和测试集\n",
    "\n",
    "把数据集拆分成两个:\n",
    "* 训练模型的训练集合\n",
    "* 验证模型的测试集合。\n",
    "\n",
    "两者比例一般是80:20。\n",
    "\n",
    "我们导入sklearn.cro-ssvalidation库中的train_test_split()方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]]\n",
      "[[1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]]\n",
      "[0 0 1 0 1 0 0 1]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步：特征缩放\n",
    "\n",
    "大部分模型算法使用两点间的欧式距离表示。\n",
    "\n",
    "但此特征在幅度、单位和范围姿态问题上变化很大。在距离计算中，高幅度的特征比低幅度特征权重更大。\n",
    "\n",
    "可用**特征标准化**或**归一化**解决。\n",
    "\n",
    "导入sklearn.preprocessing库的Stan-dardScalar类。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77459667 -0.57735027  1.29099445 -0.14517571 -0.28991038]\n",
      " [-0.77459667  1.73205081 -0.77459667 -1.20367201 -0.86973113]\n",
      " [ 1.29099445 -0.57735027 -0.77459667 -0.27748775  0.20707884]\n",
      " [ 1.29099445 -0.57735027 -0.77459667  0.64869652  0.62123652]\n",
      " [-0.77459667 -0.57735027  1.29099445 -1.60060813 -1.36672035]\n",
      " [-0.77459667  1.73205081 -0.77459667  1.44256875  1.53238343]\n",
      " [-0.77459667 -0.57735027  1.29099445 -0.04226635 -1.03539421]\n",
      " [ 1.29099445 -0.57735027 -0.77459667  1.17794467  1.20105728]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.77459667  1.29099445 -0.57735027  0.13046561 -0.09355807]\n",
      " [ 1.29099445 -0.77459667 -0.57735027 -0.52186246 -0.59901468]\n",
      " [ 1.29099445 -0.77459667 -0.57735027  1.17419053  1.23812568]\n",
      " [ 1.29099445 -0.77459667 -0.57735027  0.65232807  0.62574556]\n",
      " [-0.77459667  1.29099445 -0.57735027  1.43512176  1.58805718]\n",
      " [-0.77459667 -0.77459667  1.73205081 -0.13046561 -0.33656606]\n",
      " [-0.77459667  1.29099445 -0.57735027 -1.17419053 -0.94894618]\n",
      " [-0.77459667 -0.77459667  1.73205081 -1.56558738 -1.47384342]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer  #替换缺失值\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder  #数据转化\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split  #数据划分\n",
    "from sklearn.preprocessing import StandardScaler  #\n",
    "\n",
    "x=df.iloc[:,:-1].values  #矩阵\n",
    "y=df.iloc[:,3].values  #向量\n",
    "\n",
    "imputer=SimpleImputer(strategy=\"mean\")  #用均值替代缺失值\n",
    "imputer=imputer.fit(x[:,1:3])\n",
    "x[:,1:3]=imputer.transform(x[:,1:3])\n",
    "\n",
    "labelencoder_x=LabelEncoder()  #初始化\n",
    "x[:,0]=labelencoder_x.fit_transform(x[:,0])  #选取第一列数据\n",
    "#创建虚变量\n",
    "ct=ColumnTransformer([(\"Country\",OneHotEncoder(),[0])],remainder=\"passthrough\")\n",
    "x=ct.fit_transform(x)\n",
    "\n",
    "labelencoder_y=LabelEncoder()\n",
    "y=labelencoder_y.fit_transform(y)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "sc_x=StandardScaler()\n",
    "x_train=sc_x.fit_transform(x_train)\n",
    "x_test=sc_x.fit_transform(x_test)\n",
    "print(x_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f03fb8992b0e5aa6a67cd56eb653950a01f214acb97d94a2178dd1aa47d1bcf"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
